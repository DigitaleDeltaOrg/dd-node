# -*- mode: ruby -*-
# vi: set ft=ruby :

# Vagrantfile API/syntax version. Don't touch unless you know what you're doing!
VAGRANTFILE_API_VERSION = "2"

Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|
  # All Vagrant configuration is done here. The most common configuration
  # options are documented and commented below. For a complete reference,
  # please see the online documentation at vagrantup.com.

  # Every Vagrant virtual environment requires a box to build off of.
  config.vm.box = "fgrehm/trusty64-lxc"

  config.vm.provider :lxc do |lxc|
      lxc.customize 'network.ipv4', '10.0.3.10/32'
  end

  # The url from where the 'config.vm.box' box will be fetched if it
  # doesn't already exist on the user's system.
  # config.vm.box_url = "http://domain.com/path/to/above.box"

  # Create a forwarded port mapping which allows access to a specific port
  # within the machine from a port on the host machine. In the example below,
  # accessing "localhost:8080" will access port 80 on the guest machine.
  config.vm.network :forwarded_port, guest: 8000, host: 8000
  config.vm.network :forwarded_port, guest: 5432, host: 2345

  # Create a private network, which allows host-only access to the machine
  # using a specific IP.
  # config.vm.network :private_network, ip: "192.168.33.10"

  # Create a public network, which generally matched to bridged network.
  # Bridged networks make the machine appear as another physical device on
  # your network.
  # config.vm.network :public_network

  # If true, then any SSH connections made will enable agent forwarding.
  # Default value: false
  config.ssh.forward_agent = true

  # Share an additional folder to the guest VM. The first argument is
  # the path on the host to the actual folder. The second argument is
  # the path on the guest to mount the folder. And the optional third
  # argument is a set of non-required options.
  # config.vm.synced_folder "/path/to/hostfolder", "/path/to/guestfolder"

  # Some of us like this one:
  # config.vm.synced_folder "../", "/srv"

  # Provider-specific configuration so you can fine-tune various
  # backing providers for Vagrant. These expose provider-specific options.
  # Example for VirtualBox:
  #
  # config.vm.provider :virtualbox do |vb|
  #   # Don't boot with headless mode
  #   vb.gui = true
  #
  #   # Use VBoxManage to customize the VM. For example to change memory:
  #   vb.customize ["modifyvm", :id, "--memory", "1024"]
  # end
  #
  # View the documentation for the provider you're using for more
  # information on available options.

  # Enable provisioning with Puppet stand alone.  Puppet manifests
  # are contained in a directory path relative to this Vagrantfile.
  # You will need to create the manifests directory and a manifest in
  # the file base.pp in the manifests_path directory.
  #
  # An example Puppet manifest to provision the message of the day:
  #
  # # group { "puppet":
  # #   ensure => "present",
  # # }
  # #
  # # File { owner => 0, group => 0, mode => 0644 }
  # #
  # # file { '/etc/motd':
  # #   content => "Welcome to your Vagrant-built virtual machine!
  # #               Managed by Puppet.\n"
  # # }
  #
  # config.vm.provision :puppet do |puppet|
  #   puppet.manifests_path = "manifests"
  #   puppet.manifest_file  = "site.pp"
  # end

  # Enable provisioning with chef solo, specifying a cookbooks path, roles
  # path, and data_bags path (all relative to this Vagrantfile), and adding
  # some recipes and/or roles.
  #
  # config.vm.provision :chef_solo do |chef|
  #   chef.cookbooks_path = "../my-recipes/cookbooks"
  #   chef.roles_path = "../my-recipes/roles"
  #   chef.data_bags_path = "../my-recipes/data_bags"
  #   chef.add_recipe "mysql"
  #   chef.add_role "web"
  #
  #   # You may also specify custom JSON attributes:
  #   chef.json = { :mysql_password => "foo" }
  # end

  # Enable provisioning with chef server, specifying the chef server URL,
  # and the path to the validation key (relative to this Vagrantfile).
  #
  # The Opscode Platform uses HTTPS. Substitute your organization for
  # ORGNAME in the URL and validation key.
  #
  # If you have your own Chef Server, use the appropriate URL, which may be
  # HTTP instead of HTTPS depending on your configuration. Also change the
  # validation key to validation.pem.
  #
  # config.vm.provision :chef_client do |chef|
  #   chef.chef_server_url = "https://api.opscode.com/organizations/ORGNAME"
  #   chef.validation_key_path = "ORGNAME-validator.pem"
  # end
  #
  # If you're using the Opscode platform, your validator client is
  # ORGNAME-validator, replacing ORGNAME with your organization name.
  #
  # If you have your own Chef Server, the default validation client name is
  # chef-validator, unless you changed the configuration.
  #
  #   chef.validation_client_name = "ORGNAME-validator"

  # Repair Vagrant UID/GID to match our current user.
  # When vagrant is used by a user that is not the default user (with UID 1000)
  # this user will experience ownership conflicts between his folders locally
  # and synced in vagrant. The code below fixes this by replacing UID for the
  # vagrant user in the Vagrant box with the UID of the user locally during
  # provisioning (but only when they differ).
  uid = `id -u`.strip()
  gid = `id -g`.strip()
  config.vm.provision "shell", inline: <<-EOF
    # Exit on first error
    set -e

    # Resolve our UID and GID
    src_uid="$(id -u vagrant)"
    target_uid="#{uid}"
    src_gid="$(id -g vagrant)"
    target_gid="#{gid}"
    echo "$target_gid"
    echo "$target_gid"

    # If the user and group ids are aligned, then exit early
    if test "$src_uid" = "$target_uid" && test "$src_gid" = "$target_gid"; then
      exit 0
    fi

    # Otherwise, update our user id and group id
    # DEV: We cannot use \`usermod\` as it complains about \`vagrant\` having a process
    # Example: UID=100; GID=101
    #  /etc/shadow: libuuid:x:100:101::/var/lib/libuuid:
    #  /etc/group: libuuid:x:101:
    sed -E "s/(vagrant:.:)$src_uid:$src_gid:/\\1$target_uid:$target_gid:/g" --in-place /etc/passwd
    sed -E "s/(vagrant:.:)$src_gid:/\\1$target_gid:/g" --in-place /etc/group

    # Update all files to the proper user and group
    find / -uid "$src_uid" 2> /dev/null | grep --invert-match -E "^(/sys|/proc)" | xargs chown "$target_uid"
    find / -gid "$src_gid" 2> /dev/null | grep --invert-match -E "^(/sys|/proc)" | xargs chgrp "$target_gid"
  EOF

  # enable provisioning with ansible
  config.vm.provision :ansible do |ansible|
    ansible.playbook = "./deploy/provision.yml"
    ansible.inventory_path = "./deploy/hosts"
    ansible.limit = "local"
    #ansible.tags = "gis"
    ansible.extra_vars = {scipypip: true}
  end

end
